Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 8
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	all
	1	clustering
	1	normalization
	3

[Wed Jul 15 23:22:55 2020]
rule normalization:
    output: /home/htran/storage/datasets/drug_resistance/dlp_results/SA535_rna_cys/normalized/SA535_cys_normalized_output.rds
    jobid: 1

[Wed Jul 15 23:31:26 2020]
Finished job 1.
1 of 3 steps (33%) done

[Wed Jul 15 23:31:26 2020]
rule clustering:
    input: /home/htran/storage/datasets/drug_resistance/dlp_results/SA535_rna_cys/normalized/SA535_cys_normalized_output.rds
    output: /home/htran/storage/datasets/drug_resistance/dlp_results/SA535_rna_cys/clustering/SA535_cys_normalized_clusters.rds
    jobid: 2

[Wed Jul 15 23:33:05 2020]
Error in rule clustering:
    jobid: 2
    output: /home/htran/storage/datasets/drug_resistance/dlp_results/SA535_rna_cys/clustering/SA535_cys_normalized_clusters.rds
    shell:
        Rscript /home/htran/Projects/farhia_project/rscript/pipeline/clustering.R -i /home/htran/storage/datasets/drug_resistance/dlp_results/SA535_rna_cys/normalized/SA535_cys_normalized_output.rds -o /home/htran/storage/datasets/drug_resistance/dlp_results/SA535_rna_cys/clustering/SA535_cys_normalized_clusters.rds -r 0.1
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: /home/htran/Projects/farhia_project/rscript/snakemake_10x/SA535_cys/.snakemake/log/2020-07-15T232254.969610.snakemake.log
