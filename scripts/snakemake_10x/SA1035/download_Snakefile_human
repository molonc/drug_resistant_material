import os

## Tickets & Libraries for analysis
library = config["library"]
MAX_MITO = config["max_mito"]
MAX_RIBO = config["max_ribo"]
MIN_PC_DETECTED = config["min_pc_detected"]
MIN_FEATURES = config["min_features"]
MIN_PC_SUM = config["min_pc_sum"]

##PROBSEG = config["probIdx"]

##P_ADJUST = config["p_adjust"]
##MIN_LOGFC = config["min_logfc"]


SOURCE_DIR = os.path.join(config['project_dir'], 'pipeline')

rule all:
    """
    Launches full snakemake pipeline, cleans up junk files at the end.
    """
    input:
        os.path.join(config['results_dir'], 'SA1035_10x_filtering_log.csv'),
        os.path.join(config['results_dir'], 'filtered', 'summary_SA1035.csv')
    
        
        
if config["download_data"]:
    rule download_data:
        """
        Runs a shell script that downloads all the data for corruptTree
        """
        params:
            human_dir = os.path.join(config['download_dir'],'human')
        output:
            directory(os.path.join(config['download_dir'],'human', '{library}'))
        shell:
            'python {SOURCE_DIR}/utils/script_tenx_human.py '
            '--library_id {wildcards.library} '
            '--download_dir {params.human_dir}'


if config["merge_data"]:
    rule merge_data:
        """
        do nothing, just keep it here to run snakemake
        """
        input:
            expand(os.path.join(config['download_dir'],'human', '{library}'), library=library)
        output:
            os.path.join(config['results_dir'], 'SA1035_human_download_log.csv')
        shell:
            'python {SOURCE_DIR}/utils/lib_info.py {input} {output}'
            
        
if config["filter_data"]:  
    rule filter_data:
        """
        Filtering data, qualification control
        """
        params:
            mouse_id=lambda wildcards: config['library'][wildcards.library]['mouse_id'],
            treatmentSt=lambda wildcards: config['library'][wildcards.library]['treatmentSt'],
            library_id=lambda wildcards: config['library'][wildcards.library]['library_id'],
            batch_info=lambda wildcards: config['library'][wildcards.library]['batch_info']
        input:
            os.path.join(config['download_dir'], 'human','{library}','{library}.rdata')
        output:
            os.path.join(config['results_dir'], 'filtered','{library}_filtered.rds')
        shell:
            'Rscript {SOURCE_DIR}/qc_filtering.R '
            '--inputfile {input} '
            '--outputfile {output} '
            '--library_id {params.library_id} '
            '--mouse_id {params.mouse_id} '
            '--treatmentSt {params.treatmentSt} '
            '--batch_info {params.batch_info} '
            '--max_mito {MAX_MITO} '
            '--max_ribo {MAX_RIBO} '
            '--min_pc_detected {MIN_PC_DETECTED} '
            '--min_features {MIN_FEATURES} '
            '--min_pc_sum {MIN_PC_SUM} '
    
if config["merge_filter_data"]:  
    rule merge_filter_data:
        """
        do nothing, just keep it here to run snakemake
        """
        input:
            expand(os.path.join(config['results_dir'],'filtered','{library}_filtered.rds'), library=library)
        output:
            os.path.join(config['results_dir'], 'SA1035_10x_filtering_log.csv')
        shell:
            'python {SOURCE_DIR}/utils/lib_info.py {input} {output}'
    
    
if config["verification_qc"]:        
    rule verification:
        """
        Verifying the QC output for this project data series
        """
        params:
            library_ids = ",".join(list(library.keys())),
            input_dir = os.path.join(config['download_dir'],'human')
        output:
            os.path.join(config['results_dir'], 'filtered', 'summary_SA1035.csv')
        shell:
            'Rscript {SOURCE_DIR}/utils/qc_verification.R -l {params.library_ids} -i {params.input_dir} -o {output}'        
   